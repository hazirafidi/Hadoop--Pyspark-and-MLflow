# Machine Learning with Hadoop, Pyspark and MLFlow



## Introduction

Hadoop is an open source framework that facilitates on storing and processing large datasets. Spark is an open source framework for big data from data streaming, ETL and Machine Learning. MLFlow is an open source framework that enable to monitor, tracking and deploy ML projects. This repo demonstrate on how to integrate of these framework as a data scientist/data analyst.

## Prerequisites

1. Install WSL [LINK](https://learn.microsoft.com/en-us/windows/wsl/install)
2. Install and setup Hadoop Cluster [LINK](https://medium.com/@hazirahmohdrafidi/install-hadoop-and-set-up-single-node-cluster-474e466db359)
3. Install and setup Spark [LINK](https://medium.com/@hazirahmohdrafidi/how-to-install-and-integrate-spark-in-jupyter-notebook-linux-or-wsl-f24644bae97)
4. Install MySQL [LINK](https://www.cyberciti.biz/faq/installing-mysql-server-on-ubuntu-22-04-lts-linux/)


## Instructions
Git clone this repo to demo on:

1. Retrieve HDFS files from Hadoop Cluster using Pyspark (PART 1)
2. ML model experimentation with MLflow (PART 2)
