# Machine Learning with Hadoop, Pyspark and MLFlow

## Introduction

Hadoop is an open source framwork that facilitates on storing and processing large datasets. Spark is an open source framework for big data from data streaing, ETL and Machine Learning. MLFlow is an open source framework that enable to monitor, tracking and deploy ML projects. This repo demonstrate on how to integrate of these framweork as a data scientist/data analyst.


### Instruction
Git clone this repo to demo on:

1. Install and setup Hadoop Cluster [https://medium.com/@hazirahmohdrafidi/install-hadoop-and-set-up-single-node-cluster-474e466db359]
2. Install and setup Spark [https://medium.com/@hazirahmohdrafidi/how-to-install-and-integrate-spark-in-jupyter-notebook-linux-or-wsl-f24644bae97]
3. Run PART 1 Notebook for the demo on acquiring the HDFS files from the Hadoop cluster using Spark.
4. Install MySQL [https://www.cyberciti.biz/faq/installing-mysql-server-on-ubuntu-22-04-lts-linux/]
5. Run PART 2 Notebook for the demo on ML model experimentation with MLflow.
